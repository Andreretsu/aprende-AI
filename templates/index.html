{% load static %}
<!DOCTYPE html>
<html lang="pt-br">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Aprende AI - Teste de Voz</title>

    <link rel="stylesheet" href="{% static '../static/style.css' %}">

    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
</head>

<body>

    <div class="container">
        <header>
            <h1>Aprende AI ü§ñ</h1>
            <p>Teste de Alfabetiza√ß√£o</p>
        </header>

        <main>
            <div class="card">
                <h2>Leia a palavra abaixo:</h2>
                <div class="palavra-destaque">CASA</div>

                <p id="status-texto" class="status">Segure o bot√£o para falar</p>
            </div>

            <button id="btn-gravar" class="btn-mic">
                <span class="material-icons">mic</span>
                <span id="btn-texto">Segure para Gravar</span>
            </button>

            <div id="resultado-container" class="resultado hidden">
                <h3>A IA ouviu:</h3>
                <p id="texto-ouvido">...</p>
                <p id="mensagem-feedback">...</p>
            </div>
        </main>

        {% csrf_token %}
    </div>

    <script>
        // 1. Elementos da Tela
        const btn = document.getElementById('btn-gravar');
        const btnTexto = document.getElementById('btn-texto');
        const statusTexto = document.getElementById('status-texto');
        const resultadoContainer = document.getElementById('resultado-container');
        const textoOuvido = document.getElementById('texto-ouvido');
        const mensagemFeedback = document.getElementById('mensagem-feedback');

        // 2. Vari√°veis de √Åudio
        let mediaRecorder;
        let audioChunks = [];

        // 3. Configurar Microfone ao carregar a p√°gina
        navigator.mediaDevices.getUserMedia({ audio: true })
            .then(stream => {
                mediaRecorder = new MediaRecorder(stream);

                // Quando o microfone captar dados, guarda no array
                mediaRecorder.ondataavailable = event => {
                    audioChunks.push(event.data);
                };

                // Quando a grava√ß√£o parar, envia para o Django
                mediaRecorder.onstop = enviarAudio;
            })
            .catch(err => {
                console.error("Erro:", err);
                statusTexto.innerText = "Erro: Microfone n√£o permitido!";
                statusTexto.style.color = "red";
                btn.disabled = true;
            });

        // 4. Eventos do Bot√£o (Mouse e Toque para celular)
        const iniciarGravacao = (e) => {
            e.preventDefault(); // Evita selecionar texto
            if (!mediaRecorder) return;

            audioChunks = []; // Limpa grava√ß√µes anteriores
            mediaRecorder.start();

            // Mudan√ßa visual
            btn.classList.add('gravando');
            btnTexto.innerText = "Gravando...";
            statusTexto.innerText = "Escutando...";
            resultadoContainer.classList.add('hidden');
        };

        const pararGravacao = (e) => {
            e.preventDefault();
            if (!mediaRecorder || mediaRecorder.state === "inactive") return;

            mediaRecorder.stop();

            // Volta visual ao normal
            btn.classList.remove('gravando');
            btnTexto.innerText = "Segure para Gravar";
            statusTexto.innerText = "Processando √°udio...";
        };

        // Adiciona os eventos (funciona no PC e no Celular)
        btn.addEventListener('mousedown', iniciarGravacao);
        btn.addEventListener('mouseup', pararGravacao);
        btn.addEventListener('touchstart', iniciarGravacao);
        btn.addEventListener('touchend', pararGravacao);

        // 5. Fun√ß√£o que envia para o Django
        function enviarAudio() {
            const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });
            const formData = new FormData();

            // 'audio_data' √© o nome que vamos buscar no views.py
            formData.append('audio_data', audioBlob, 'gravacao.wav');

            // Pega o token CSRF que est√° escondido no HTML
            const csrfToken = document.querySelector('[name=csrfmiddlewaretoken]').value;

            fetch('/processar-audio/', {
                method: 'POST',
                headers: { 'X-CSRFToken': csrfToken },
                body: formData
            })
                .then(response => response.json())
                .then(data => {
                    // Atualiza a tela com a resposta da IA
                    textoOuvido.innerText = `"${data.texto}"`;
                    mensagemFeedback.innerText = data.mensagem;

                    statusTexto.innerText = "Pronto!";
                    resultadoContainer.classList.remove('hidden');
                })
                .catch(erro => {
                    console.error('Erro na requisi√ß√£o:', erro);
                    statusTexto.innerText = "Erro ao conectar com a IA.";
                });
        }
    </script>
</body>

</html>